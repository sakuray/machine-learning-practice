'''
    元算法：将多个算法组合起来，进行选择
    优点：泛化错误率低，易编码，可以应用在大部分分类器上，无参数调整
    缺点：对离群点敏感
    适用数据类型：数值型和标称型
    Adaboost:训练多个弱分类器。
             每个样本有一个权重，这些权重构成向量D，训练出一个弱分类器，根据错误率调整权重，错的样本权重会升高，权重计算是：
                θ = 错误率
                α=1/2 ln(1-θ/θ）
                D = D*e^-α/sum(D)  成功
                D = D*e^α/sum(D)   失败
            （一般情况有些分类的样本太小，这样可以提升少数情况的重要度）
        使用单层决策树
'''